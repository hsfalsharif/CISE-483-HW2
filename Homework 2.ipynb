{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW 2 (Due date: Sunday, Oct. 25th, at 11:59 PM)\n",
    "\n",
    "# Note: Group work is allowed! However, you need to do it according to the following conditions: \n",
    "\n",
    "    1. Up to 3 students per group. \n",
    "    2. No more than 2 students from the same major can be in 1 group. \n",
    "    3. No communication between different groups, please.\n",
    "    4. Each group need to submit one HW, and all members will receive the same HW score. \n",
    "    5. You still have the choice to work individually, or as a group of 2 students. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1 (30 points) \n",
    "\n",
    "### Which of the following are true and which are false? Explain your answers.\n",
    "\n",
    "1. Depth-first search always expands at least as many nodes as A* search with an admissible heuristic.\n",
    "\n",
    "2. h(n)=0 is an admissible heuristic for robot navigation from point A to point B. \n",
    "\n",
    "3. A* is of no use in robotics because percepts, states, and actions are continuous.\n",
    "\n",
    "4. A* algorithm is optimal even if the heuristic is inadmissable. \n",
    "\n",
    "5. For a mathematical optimization problem in which we are minimizing an objective function $f$,  then the solution to $\\nabla f=0$ leads to at least a local minimum. Here, we assume that $f$ is differentiable. \n",
    "\n",
    "6. Uniform-cost search is a special case of A* search."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer: \n",
    "\n",
    "1. True. Depth-first search might expand at least as many nodes as A* but it will never expand less nodes than A*. This is because A* is an informed search algorithm whereas depth-first search is blind so is considered to be less efficient. Depth-first has no way to tell if it is going in the right direction or not whereas A* search does.\n",
    "\n",
    "2. True. h(n) = 0 is an admissible heuristic for robot navigation from point A to point B because it never overestimates the cost to reach B. It should be noted however that it is not the most efficient heuristic function because it is considered to be blind and performs more steps to find the optimal path than does an algorithm such as A*.\n",
    "\n",
    "3. False. A* can be written and configured to run continuously so that it adapts to a changing environment to always be able to find the shortest path to the goal.\n",
    "\n",
    "4. False. An inadmissable heuristic would overestimate the cost of the path to reach the goal so would not produce an optimal solution.\n",
    "\n",
    "5. True. Since we are assuming that f is differentiable then solving for $\\nabla f=0$ will lead to a convergence at a local minimum.\n",
    "\n",
    "6. True. Uniform-cost search is A* search when h(n) = 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2 (30 points) \n",
    "\n",
    "### In your own words, briefly answer the following questions: \n",
    "\n",
    "1. Compare the propositional and predicate logics, and provide an example elaborating on the difference(s) between the two. \n",
    "\n",
    "2. Discuss, with examples (different from presentation slides or the textbook), three different ways of obtaining probabilities of events. \n",
    "\n",
    "3. Discuss how can a robot make decisions under uncertainty, i.e., a robot with possibly faulty sensor data, low-rosulution camera, low-computational cababilities. \n",
    "\n",
    "4. Given the full joint distribution shown in Figure dentist-joint-table, calculate the following:\n",
    "\n",
    "    a. P(toothache).\n",
    "    \n",
    "    b. P(Cavity).\n",
    "    \n",
    "    c. P(Cavity | catch).\n",
    "    \n",
    "    d. P(Cavity | toothache ‚à® catch).\n",
    "    \n",
    "   ![FJPT](https://static.wixstatic.com/media/7e9efc_55cf090fa12f466b9be2e1bb729d5b6d~mv2.png)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer: \n",
    "\n",
    "1. Propositional logic is made up of statements that can only be true or false. Combinations of these statements tied using logical connectives can describe more complex descriptions but the end result must be either true or false. Predicate logic on the other hand is logic that is used to describe more complex relationships between general or specific entities. Predicate logic uses existential and universal quantifiers to describe these generalisations and specificities. One contrasting example between the two types of logic is the way the statement \"It is not raining in Guatemala\" might be described. In propositional logic this might be represented using R which describes the fact that \"It is raining in Guatemala\" so to describe the previous statement we would claim $\\lnot R$. In predicate logic we could describe it more generally if we desired by defining a function R(x) that describes the fact that it is raining in country x, and then claiming that $\\exists\\lnot R(x)$. We could also describe it more specifically by saying $\\lnot R($Guatemala$)$. It is clear that the descriptive capabilities of descriptive and predicate logics is quite different.\n",
    "\n",
    "2. The three different ways for obtaining probabilities that have been discussed are the a priori classical method, the empirical classical method, and the subjective method. I will now introduce my own examples for each of the three. For the a priori method, an example could be the fact that the chances of drawing a Jack from a standard deck of cards is $\\frac{1}{13}$ since there are 4 Jacks out of the 52 cards. An example for the empirical method could be that the probability of a startup in a particular town failing is 0.73, which could have been computed by revising the historical data of all the startups that have failed in that town. For the subjective method I could say that the probability of me ordering something that I will like at any given restaurant is 0.65 because that is what I feel subjectively based on my completely biased and judgemental memory of my past restaurant experiences.\n",
    "\n",
    "3. Uncertainties that the robot may encounter or deal with are represented using probabilities. So for example an ultrasonic sensor may have an specified error of 5% which must be accounted for in the robot's decision-making computations. Before making a decision, the robot will calculate probabilistic estimates based on these sources of error and will then perform the action with the highest probability for it to achieve its required goal in the most favourable way possible.\n",
    "\n",
    "4.\n",
    "a) P(toothache) = 0.108 + 0.016 + 0.012 + 0.064 = 0.2\n",
    "\n",
    "b) P(cavity) = 0.108 + 0.012 + 0.072 + 0.008 = 0.2\n",
    "\n",
    "c) P(cavity | catch) = (0.108 + 0.072) / (0.108 + 0.072 + 0.016 + 0.144) = 0.5294\n",
    "\n",
    "d) P(cavity | toothache v catch) = (0.108 + 0.072 + 0.012) / (0.108 + 0.072 + 0.016 + 0.144 + 0.012 + 0.016 + 0.064) = 0.4444\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 3 (60 points) \n",
    "\n",
    "## Consider the following map: \n",
    "\n",
    "![SearchTree](https://static.wixstatic.com/media/7e9efc_fb53c0c6d9ae46aea970b2897b47543e~mv2.png)\n",
    "\n",
    "## In-class, we explored the Greedy Best-First Search and A* Search algorithms for the above map. Here, your task is to implement these two algorithms, and compare their outcomes. Assume that we have a driveless car in Arad and we want to navigate its way to Bucharest. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## YOUR CODE GOES HERE "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### YOUR COMMENTS ON THE RESULTS GO HERE  ... "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Consider the problem of minimizing the function of two variables $$f(x,y) = 3x^2+y^4,$$\n",
    "## Apply the gradient descent method with $(x_0,y_0)=(1,‚àí2)$ as the starting point and with $\\alpha^ùëò=\\frac{1}{2^{(ùëò+1)}}$ at iteration $k$. Stop if $\\Delta f < 20$. Make your code print the candidate solution $(x_k,y_k)$ at every iteration. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## YOUR CODE GOES HERE "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### YOUR COMMENTS ON THE RESULTS GO HERE  ... "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}